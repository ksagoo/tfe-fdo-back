parser.add_argument(
    "--all-fqdns",
    action="store_true",
    help="Perform reverse lookup on all known FQDNs returned by Akamai PAPI"
)


def get_all_fqdns(session, base_url, debug=False):
    """Fetches all FQDNs from Akamai PAPI /hostnames."""
    url = f"{base_url}/papi/v1/hostnames"
    print(f"[INFO] Fetching all hostnames via {url}")

    resp = session.get(url, timeout=60)
    if resp.status_code != 200:
        print(f"[ERROR] Failed to fetch all hostnames: HTTP {resp.status_code}")
        return []

    data = resp.json() or {}
    if debug:
        write_json(data, "output/raw_all_hostnames.json")

    items = []
    if "hostnames" in data:
        hostnames = data["hostnames"]
        if isinstance(hostnames, dict):
            items = hostnames.get("items", [])
        elif isinstance(hostnames, list):
            items = hostnames
    elif "items" in data:
        items = data["items"]

    fqdns = []
    for entry in items:
        cname_from = entry.get("cnameFrom", "")
        if cname_from:
            fqdns.append(cname_from)





if args.all_fqdns:
    fqdns = get_all_fqdns(session, base_url, debug=args.debug)
    print(f"\n==== Running reverse lookup for {len(fqdns)} FQDNs ====\n")

    for fqdn in fqdns:
        print(f"\n>>> Reverse lookup for {fqdn}")
        reverse_fqdn_lookup(session, base_url, fqdn, debug=args.debug)
    return
    print(f"[INFO] Retrieved {len(fqdns)} total FQDNs from PAPI.")
    return sorted(set(fqdns))
